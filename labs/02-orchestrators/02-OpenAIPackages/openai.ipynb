{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02 - Using the OpenAI Library\n",
    "\n",
    "In the [first](../01-AzureOpenAIAPI/azureopenaiapi.ipynb) lab, we walked through calling the Azure OpenAI API directly to list available model deployments and submit a prompt for completion. An easier way to work with an API is to use a *Library*. A Library is a collection of packages and modules that allow reusable code to be shared with the community.\n",
    "\n",
    "In this lab, we'll use the OpenAI Python library to perform the same operations as we did in the first lab.\n",
    "\n",
    "## Setup\n",
    "\n",
    "In Python, we first use the `pip` tool to install the OpenAI library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install openai"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we use the `import` statement to let our application know that we're going to be using the OpenAI library in our code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to provide our Azure OpenAI API key and endpoint details\n",
    "\n",
    "> :bulb: **HINT:** You can get the key and endpoint details from the Azure Portal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY = \"<YOUR API KEY>\"\n",
    "RESOURCE_ENDPOINT = \"<YOUR AZURE OPENAI ENDPOINT>\" # For example https://<your azure open ai instance>.openai.azure.com/"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The OpenAI library needs some configuration parameters set to allow it to work with the OpenAI service. We'll set the following parameters.\n",
    "\n",
    "Parameter name | Description\n",
    "--- | ---\n",
    "`openai.api_type` | We set this value to indicate whether we're using the native OpenAI service, or the Azure OpenAI service\n",
    "`openai.api_key` | This is the value for our API key\n",
    "`openai.api_base` | This is the resource endpoint for the OpenAI service we're using\n",
    "`openai_api_version` | This is the version of the API we are going to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_type = \"azure\"\n",
    "openai.api_key = API_KEY\n",
    "openai.api_base = RESOURCE_ENDPOINT\n",
    "openai.api_version = \"2023-03-15-preview\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the list of available Model Deployments\n",
    "\n",
    "We can now call the `Deployment.list()` method of the OpenAI library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.Deployment.list()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll see that the result is the same JSON data that we got when we called the API directly.\n",
    "\n",
    "## Send a prompt to Azure OpenAI using the OpenAI library\n",
    "\n",
    "Ok, now that we have the list of deployment models, let's try to do a Completion.\n",
    "\n",
    "We need to provide the model and deployment details. The value to use for `COMPLETION_MODEL` appears as `model` in the results from the previous step and the value for `DEPLOYMENT_ID` appears as `id`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COMPLETION_MODEL = \"<YOUR MODEL NAME>\" # Replace with the name of the model, for example \"text-davinci-003\"\n",
    "DEPLOYMENT_ID = \"<YOUR DEPLOYMENT ID>\" # Replace with your deployment id, for example \"text-davinci-003\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we've configured the OpenAI Python library in the previous steps, we can go ahead and call the completions method to generate a response. We'll call the `Completion.create()` method and pass in the name of our `model`, the `deployment_id` and the `prompt` we want to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = openai.Completion.create(\n",
    "    model = COMPLETION_MODEL,\n",
    "    deployment_id = DEPLOYMENT_ID,\n",
    "    prompt = \"This is a test\",\n",
    ")\n",
    "\n",
    "print(r)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, the response above should be the same JSON data that we got when we called the API directly, containing details of the model we called, the response that was generated and the token usage.\n",
    "\n",
    "We could also just extract the generated response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(r.choices[0].text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The OpenAI library provides a more concise way to work with the OpenAI API. Once we've set up the initial parameters, we don't need to send them each time as we need to do with a direct API call. It's also easier to add information such as prompts to the call, as we can pass those values in as part of the call to the OpenAI library methods instead of having to pass in JSON objects as part of the request body.\n",
    "\n",
    "You can find more details about the completions API in the reference documentation:\n",
    "\n",
    "https://platform.openai.com/docs/api-reference/completions/create\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
